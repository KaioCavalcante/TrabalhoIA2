{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UIR2V1A6nag_",
        "outputId": "10824052-df98-4b80-bae9-ae1832e69fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF: 2.19.0\n",
            "GPUs visíveis: []\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TF:\", tf.__version__)\n",
        "print(\"GPUs visíveis:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "if not os.path.exists('/content/trashnet'):\n",
        "    print(\"Baixando o repositório do TrashNet...\")\n",
        "    !git clone https://github.com/garythung/trashnet.git\n",
        "else:\n",
        "    print(\"Repositório já baixado.\")\n",
        "\n",
        "zip_path = \"/content/trashnet/data/dataset-resized.zip\"\n",
        "extract_path = \"/content/dataset_final\"\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\"Descompactando {zip_path}...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(extract_path)\n",
        "    print(\"Descompactação concluída!\")\n",
        "else:\n",
        "    print(\"Erro: Arquivo zip não encontrado no repositório.\")"
      ],
      "metadata": {
        "id": "J8KeOu3lnfok",
        "outputId": "6492fb57-3953-4ba0-9a93-a3f8ab2eb17f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando o repositório do TrashNet...\n",
            "Cloning into 'trashnet'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 45 (delta 6), reused 0 (delta 0), pack-reused 33 (from 1)\u001b[K\n",
            "Receiving objects: 100% (45/45), 40.64 MiB | 39.82 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Descompactando /content/trashnet/data/dataset-resized.zip...\n",
            "Descompactação concluída!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aolco1aEnahH"
      },
      "outputs": [],
      "source": [
        "import pydot\n",
        "print(\"Pydot version:\", pydot.__version__)\n",
        "import shutil\n",
        "print(\"Graphviz no PATH:\", shutil.which(\"dot\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjBFEeCoEZyk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.utils as utils\n",
        "from   tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from   tensorflow.keras.models import Sequential\n",
        "from   tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, ZeroPadding2D\n",
        "from   tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from   tensorflow.keras.utils import plot_model\n",
        "from   tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from   pathlib import Path\n",
        "from   tensorflow.keras import models, layers, optimizers\n",
        "from   sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnaQUEVfoTxv"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "dataset = load_dataset(\"garythung/trashnet\", split=\"train\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5TLBlHQKM10"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGY0vq9PKNeF"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "\n",
        "possible_paths = [\n",
        "    Path(\"/content/dataset_final/dataset-resized\"),\n",
        "    Path(\"/content/trashnet/data/dataset-resized\"),\n",
        "    Path(\"/content/dataset-resized\")\n",
        "]\n",
        "\n",
        "data_path = None\n",
        "for p in possible_paths:\n",
        "    if p.exists():\n",
        "        data_path = p\n",
        "        break\n",
        "\n",
        "\n",
        "if data_path:\n",
        "    print(f\"✅ Pasta de imagens encontrada em: {data_path}\")\n",
        "    print(\"Classes encontradas:\", [d.name for d in data_path.iterdir() if d.is_dir()])\n",
        "else:\n",
        "    print(\"❌ Erro: A pasta do dataset não foi encontrada. Rode a célula de download novamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irAiTvSJKV1O"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "data_path = Path(\"/content/dataset_final/dataset-resized\")\n",
        "print(\"Classes encontradas:\", [d.name for d in data_path.iterdir() if d.is_dir()])\n",
        "\n",
        "data = []\n",
        "for folder in data_path.iterdir():\n",
        "    if folder.is_dir():\n",
        "        file_count = len(list(folder.glob(\"*\")))\n",
        "        data.append({\"Folder Name\": folder.name, \"File Count\": file_count})\n",
        "\n",
        "count = pd.DataFrame(data).set_index(\"Folder Name\")\n",
        "count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thl-80DCKV4k"
      },
      "outputs": [],
      "source": [
        "print(f'Total {count.sum()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NarzRjWXKV8e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_imgs(item_dir, top=10):\n",
        "    all_item_dirs = os.listdir(item_dir)\n",
        "    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:5]\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for idx, img_path in enumerate(item_files):\n",
        "        plt.subplot(5, 5, idx+1)\n",
        "\n",
        "        img = plt.imread(img_path)\n",
        "        plt.tight_layout()\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.title(os.path.basename(item_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saGHdUXUKWDA"
      },
      "outputs": [],
      "source": [
        "plot_imgs(data_path / 'cardboard')\n",
        "plot_imgs(data_path / 'glass')\n",
        "plot_imgs(data_path / 'metal')\n",
        "plot_imgs(data_path / 'paper')\n",
        "plot_imgs(data_path / 'plastic')\n",
        "plot_imgs(data_path / 'trash')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngI-SiQkKfFB"
      },
      "outputs": [],
      "source": [
        "# Define variable for requirements\n",
        "batch_size = 30\n",
        "target_size = (128, 128)\n",
        "\n",
        "validation_split = 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqYZQNB6nahO"
      },
      "outputs": [],
      "source": [
        "train_img_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=validation_split,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.5,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    rotation_range=50,\n",
        "    shear_range=0.3,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_data_img_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=validation_split\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_uXB7ECKfH7"
      },
      "outputs": [],
      "source": [
        "train_data = train_img_generator.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "test_data = test_data_img_generator.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiSCjnzUKfK4"
      },
      "outputs": [],
      "source": [
        "# Separate train Data\n",
        "train_data = train_img_generator.flow_from_directory(data_path,\n",
        "                                                        subset=\"training\",\n",
        "                                                        seed=133,\n",
        "                                                        target_size=target_size,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='categorical',\n",
        "                                                        color_mode='rgb',\n",
        "                                                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAmBOwIeKkpL"
      },
      "outputs": [],
      "source": [
        "# Separate validation Data\n",
        "test_data = test_data_img_generator.flow_from_directory(data_path,\n",
        "                                                        subset=\"validation\",\n",
        "                                                        seed=133,\n",
        "                                                        target_size=target_size,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='categorical',\n",
        "                                                        color_mode='rgb',\n",
        "                                                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAkHUFNtKktK"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(ZeroPadding2D(padding=(1, 1), input_shape=(target_size[0], target_size[1], 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdAL9NEJnahQ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(\"Python do notebook:\", sys.executable)\n",
        "\n",
        "!{sys.executable} -m pip install pydot graphviz\n",
        "\n",
        "import pydot\n",
        "print(\"Pydot carregado de:\", pydot.__file__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VoJMIeTnahQ"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "print(\"dot no sistema:\", shutil.which(\"dot\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk9sOQ2VKpte"
      },
      "outputs": [],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH_PQAXgKpwK"
      },
      "outputs": [],
      "source": [
        "ES = EarlyStopping(monitor='val_loss', mode='min', patience=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ca494chKubY"
      },
      "outputs": [],
      "source": [
        "RLROP = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.1, min_lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPy54Q7aKud2"
      },
      "outputs": [],
      "source": [
        "MCH = ModelCheckpoint('trash.h5', monitor='val_loss', mode='min', save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MKEzdFkKzlq"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
        "             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFU77ZminahR"
      },
      "outputs": [],
      "source": [
        "print(\"Classes e índices:\", train_data.class_indices)\n",
        "print(\"Número de classes:\", train_data.num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIlclQbtnahR"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_data,\n",
        "    callbacks=[ES, RLROP, MCH]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFGmBhNEnahS"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss, acc = model.evaluate(test_data)\n",
        "print(f\"Loss de validação: {loss:.4f}\")\n",
        "print(f\"Acurácia de validação: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofaDC2OfKzqs"
      },
      "outputs": [],
      "source": [
        "best_score = max(history.history['val_categorical_accuracy'] )\n",
        "print(f\"Best Validation score is: {best_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8mJp3AMK5c8"
      },
      "outputs": [],
      "source": [
        "# Accuracy on train data :\n",
        "accuracy = history.history['categorical_accuracy']\n",
        "\n",
        "# Accuracy on test data :\n",
        "val_accuracy = history.history['val_categorical_accuracy']\n",
        "epochs = range(1, len(accuracy) + 1)  # Epochs\n",
        "\n",
        "# Accuracy line plot :\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, accuracy, 'b', label='train accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='test accuracy')\n",
        "plt.title('Accuracy plot')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CY5O-1QK5gV"
      },
      "outputs": [],
      "source": [
        "classes = train_data.class_indices\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfIoNHipnahS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder = \"/content/dataset_final/dataset-resized/paper\"\n",
        "print(os.listdir(folder)[:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HPEy7ppK_is"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image as utils\n",
        "\n",
        "img_path = \"/content/dataset_final/dataset-resized/paper/paper11.jpg\"\n",
        "\n",
        "img = utils.load_img(\n",
        "    img_path,\n",
        "    color_mode='rgb',\n",
        "    target_size=target_size,\n",
        "    interpolation='nearest'\n",
        ")\n",
        "\n",
        "img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WbL5ihiK_lo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "img_array = utils.img_to_array(img)\n",
        "img_array = img_array / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "pred = model.predict(img_array)\n",
        "\n",
        "idx_to_class = {v: k for k, v in train_data.class_indices.items()}\n",
        "\n",
        "pred_class_idx = np.argmax(pred, axis=1)[0]\n",
        "print(\"Classe prevista:\", idx_to_class[pred_class_idx])\n",
        "print(\"Distribuição de probabilidade:\", pred[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWkEOJ7KnahT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "test_data.shuffle = False\n",
        "\n",
        "y_true = test_data.classes\n",
        "y_pred_proba = model.predict(test_data)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "labels = list(test_data.class_indices.keys())\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.title(\"Matriz de confusão\")\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnn1-101nahT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}